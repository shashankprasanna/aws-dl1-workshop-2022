{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a82499f-d8f6-4636-a4e4-5f5fc5b323c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "# List of changes:\n",
    "# - loading habana module\n",
    "# - added support for prefetching to HPU\n",
    "# - added profiling callbacks support\n",
    "# - changed include paths of modules\n",
    "# - flag for setting tensorflow global seed\n",
    "# - include mechanism for dumping tensors\n",
    "\n",
    "# Copyright (C) 2020-2021 Habana Labs, Ltd. an Intel Company"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd029303-e4b4-4ab6-a868-eaae9d1f1891",
   "metadata": {},
   "source": [
    "# TensorFlow Keras ResNet50 Example on Habana Gaudi<sup>TM</sup>\n",
    "\n",
    "##### This example demonstrates how to train Keras ResNet50 on Habana Gaudi<sup>TM</sup> device with TensorFlow framework. The neural network is built with Keras APIs, and trained with synthetic data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-washer",
   "metadata": {},
   "source": [
    "## Load TensorBoard extension for Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4dfb737",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba758009-a4ff-4afd-9a74-fceb7a566436",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "continental-harassment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "from absl import logging\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-europe",
   "metadata": {},
   "source": [
    "### Import Python packages from Habana Model-References github repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "serious-maryland",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TensorFlow.common.modeling import performance\n",
    "from TensorFlow.common.training import controller\n",
    "from TensorFlow.common.library_loader import load_habana_module\n",
    "from TensorFlow.common.debug import dump_callback\n",
    "from TensorFlow.common.horovod_helpers import synapse_logger_init\n",
    "from TensorFlow.common.tb_utils import write_hparams_v2\n",
    "\n",
    "from TensorFlow.utils.logs import logger\n",
    "from TensorFlow.utils.misc import distribution_utils\n",
    "from TensorFlow.utils.misc import keras_utils\n",
    "from TensorFlow.utils.misc import model_helpers\n",
    "\n",
    "from TensorFlow.computer_vision.common import imagenet_preprocessing\n",
    "from TensorFlow.computer_vision.Resnets.resnet_keras.local_flags import core as flags_core\n",
    "from TensorFlow.computer_vision.Resnets.utils.optimizers.keras import lars_util\n",
    "from TensorFlow.computer_vision.Resnets.resnet_keras import common\n",
    "from TensorFlow.computer_vision.Resnets.resnet_keras import resnet_runnable\n",
    "from TensorFlow.computer_vision.Resnets.resnet_keras.common import adjust_batch_size\n",
    "\n",
    "from central.habana_model_yaml_config import HabanaModelYamlConfig\n",
    "from central.habana_model_runner_utils import HabanaEnvVariables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-insurance",
   "metadata": {},
   "source": [
    "## Define training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "close-market",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.set_verbosity(logging.INFO)\n",
    "# define keras args\n",
    "common.define_keras_flags()\n",
    "# define habana args\n",
    "common.define_habana_flags()\n",
    "# define LARS args\n",
    "lars_util.define_lars_flags()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-rouge",
   "metadata": {},
   "source": [
    "## Define function to parse arguments from yaml configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "seasonal-tackle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args_yaml_config(config_file):\n",
    "    yaml_config = HabanaModelYamlConfig('resnet_keras', config_file)\n",
    "    \n",
    "    env_args = yaml_config.get_env_vars()\n",
    "    model_params=yaml_config.get_parameters()\n",
    "    \n",
    "    cmd_args = []\n",
    "    exclude_fields = ['use_horovod', 'num_workers_per_hls', 'hls_type']\n",
    "    yaml_config.add_parameters_except(cmd_args, exclude_fields)\n",
    "    \n",
    "    return env_args, cmd_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-failure",
   "metadata": {},
   "source": [
    "## Define functions for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "floating-thursday",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_stats(runnable, time_callback):\n",
    "    \"\"\"Normalizes and returns dictionary of stats.\n",
    "\n",
    "    Args:\n",
    "      runnable: The module containing all the training and evaluation metrics.\n",
    "      time_callback: Time tracking callback instance.\n",
    "\n",
    "    Returns:\n",
    "      Dictionary of normalized results.\n",
    "    \"\"\"\n",
    "    stats = {}\n",
    "\n",
    "    if not runnable.flags_obj.skip_eval:\n",
    "        stats['eval_loss'] = runnable.test_loss.result().numpy()\n",
    "        stats['eval_acc'] = runnable.test_accuracy.result().numpy()\n",
    "\n",
    "        stats['train_loss'] = runnable.train_loss.result().numpy()\n",
    "        stats['train_acc'] = runnable.train_accuracy.result().numpy()\n",
    "\n",
    "    if time_callback:\n",
    "        timestamp_log = time_callback.timestamp_log\n",
    "        stats['step_timestamp_log'] = timestamp_log\n",
    "        stats['train_finish_time'] = time_callback.train_finish_time\n",
    "        if time_callback.epoch_runtime_log:\n",
    "            stats['avg_exp_per_second'] = time_callback.average_examples_per_second\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "announced-pendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_train_iterations(flags_obj):\n",
    "    \"\"\"Returns the number of training steps, train and test epochs.\"\"\"\n",
    "    \n",
    "    train_steps = (\n",
    "        imagenet_preprocessing.NUM_IMAGES['train'] // adjust_batch_size(flags_obj.batch_size))\n",
    "    train_epochs = flags_obj.train_epochs\n",
    "\n",
    "    if flags_obj.train_steps:\n",
    "        train_steps = min(flags_obj.train_steps, train_steps)\n",
    "        train_epochs = 1\n",
    "\n",
    "    eval_steps = (\n",
    "        imagenet_preprocessing.NUM_IMAGES['validation'] // flags_obj.batch_size)\n",
    "\n",
    "    return train_steps, train_epochs, eval_steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "advanced-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _steps_to_run(steps_in_current_epoch, steps_per_epoch, steps_per_loop):\n",
    "    \"\"\"Calculates steps to run on device.\"\"\"\n",
    "    \n",
    "    if steps_per_loop <= 0:\n",
    "        raise ValueError('steps_per_loop should be positive integer.')\n",
    "    if steps_per_loop == 1:\n",
    "        return steps_per_loop\n",
    "    return min(steps_per_loop, steps_per_epoch - steps_in_current_epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-mauritius",
   "metadata": {},
   "source": [
    "## Define function to run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "alien-moisture",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(flags_obj):\n",
    "    \"\"\"Run ResNet50 training with synthetic data and eval loop using custom training loops.\n",
    "\n",
    "    Args:\n",
    "      flags_obj: An object containing parsed flag values.\n",
    "\n",
    "    Raises:\n",
    "      ValueError: If fp16 is passed as it is not currently supported.\n",
    "\n",
    "    Returns:\n",
    "      Dictionary of training and eval stats.\n",
    "    \"\"\"\n",
    "    \n",
    "    keras_utils.set_session_config(\n",
    "        enable_eager=flags_obj.enable_eager,\n",
    "        enable_xla=flags_obj.enable_xla)\n",
    "    performance.set_mixed_precision_policy(flags_core.get_tf_dtype(flags_obj))\n",
    "\n",
    "    # set data format\n",
    "    data_format = flags_obj.data_format\n",
    "    \n",
    "    if data_format is None:\n",
    "        data_format = ('channels_first'\n",
    "                       if tf.test.is_built_with_cuda() else 'channels_last')\n",
    "    tf.keras.backend.set_image_data_format(data_format)\n",
    "\n",
    "    batch_size = flags_obj.batch_size\n",
    "    model_dir = flags_obj.model_dir\n",
    "\n",
    "    strategy = distribution_utils.get_distribution_strategy(\n",
    "        distribution_strategy=flags_obj.distribution_strategy,\n",
    "        num_gpus=flags_obj.num_gpus,\n",
    "        all_reduce_alg=flags_obj.all_reduce_alg,\n",
    "        num_packs=flags_obj.num_packs,\n",
    "        tpu_address=flags_obj.tpu)\n",
    "    \n",
    "    train_writer, eval_writer = None, None\n",
    "    if flags_obj.enable_tensorboard:\n",
    "        import os\n",
    "        train_writer = tf.summary.create_file_writer(model_dir)\n",
    "        eval_writer = tf.summary.create_file_writer(os.path.join(model_dir, 'eval'))\n",
    "        write_hparams_v2(train_writer, flags_obj.flag_values_dict())\n",
    "    \n",
    "\n",
    "    per_epoch_steps, train_epochs, eval_steps = get_num_train_iterations(\n",
    "        flags_obj)\n",
    "    steps_per_loop = min(flags_obj.steps_per_loop, per_epoch_steps)\n",
    "    train_steps = train_epochs * per_epoch_steps\n",
    "\n",
    "    logging.info(\n",
    "        'Training %d epochs, each epoch has %d steps, '\n",
    "        'total steps: %d; Eval %d steps', train_epochs, per_epoch_steps,\n",
    "        train_steps, eval_steps)\n",
    "    \n",
    "    time_callback = keras_utils.TimeHistory(\n",
    "        batch_size,\n",
    "        flags_obj.log_steps,\n",
    "        summary_writer=train_writer,\n",
    "        batch_size_per_node=flags_obj.batch_size)\n",
    "    \n",
    "    profiler_callback = None\n",
    "    if flags_obj.profile_steps is not None:\n",
    "        profiler_callback = keras_utils.get_profiler_callback(\n",
    "            model_dir,\n",
    "            flags_obj.profile_steps,\n",
    "            flags_obj.enable_tensorboard,\n",
    "            per_epoch_steps)\n",
    "    with distribution_utils.get_strategy_scope(strategy):\n",
    "        runnable = resnet_runnable.ResnetRunnable(flags_obj, time_callback,\n",
    "                                                  train_steps,\n",
    "                                                  per_epoch_steps,\n",
    "                                                  profiler_callback)\n",
    "\n",
    "    eval_interval = flags_obj.epochs_between_evals * per_epoch_steps\n",
    "    checkpoint_interval = (\n",
    "        per_epoch_steps if flags_obj.enable_checkpoint_and_export else None)\n",
    "    summary_interval = per_epoch_steps if flags_obj.enable_tensorboard else None\n",
    "\n",
    "    checkpoint_manager = tf.train.CheckpointManager(\n",
    "        runnable.checkpoint,\n",
    "        directory=model_dir,\n",
    "        max_to_keep=10,\n",
    "        step_counter=runnable.global_step,\n",
    "        checkpoint_interval=checkpoint_interval)\n",
    "\n",
    "    train_steps=per_epoch_steps * train_epochs\n",
    "\n",
    "    resnet_controller = controller.Controller(\n",
    "        strategy,\n",
    "        runnable.train,\n",
    "        runnable.evaluate,\n",
    "        global_step=runnable.global_step,\n",
    "        steps_per_loop=steps_per_loop,\n",
    "        train_steps=train_steps,\n",
    "        checkpoint_manager=checkpoint_manager,\n",
    "        summary_interval=summary_interval,\n",
    "        eval_steps=eval_steps,\n",
    "        eval_interval=eval_interval)\n",
    "\n",
    "    time_callback.on_train_begin()\n",
    "    resnet_controller.train(evaluate=not flags_obj.skip_eval)\n",
    "    time_callback.on_train_end()\n",
    "\n",
    "    stats = build_stats(runnable, time_callback)\n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-resistance",
   "metadata": {},
   "source": [
    "## Parse the training arguments from yaml config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "identified-luxembourg",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet_keras\n",
      "{'TF_ENABLE_BF16_CONVERSION': 1, 'USE_LARS_OPTIMIZER': 1, 'TF_ALLOW_CONTROL_EDGES_IN_HABANA_OPS': 1, 'HABANA_NCCL_COMM_API': True, 'TF_DISABLE_MKL': 1}\n",
      "{'use_synthetic_data': True, 'skip_eval': True, 'batch_size': 256, 'steps_per_loop': 100, 'log_steps': 200, 'model_dir': '/root/tmp/resnet/', 'enable_tensorboard': True, 'data_format': 'channels_last', 'train_steps': 1000, 'use_horovod': False, 'optimizer': 'LARS', 'lr_schedule': 'polynomial', 'data_loader_image_type': 'bf16', 'weight_decay': 0.0001, 'label_smoothing': 0.1, 'base_learning_rate': 2.5, 'warmup_epochs': 3, 'distribution_strategy': 'off', 'num_gpus': 0, 'single_l2_loss_op': True}\n"
     ]
    }
   ],
   "source": [
    "env_args, cmd_args = parse_args_yaml_config('resnet50_keras_lars_bf16_1card.yaml')\n",
    "\n",
    "cmd_args.insert(0, ' ') # workaround cmd line args \n",
    "argv = flags.FLAGS(cmd_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "insured-japan",
   "metadata": {},
   "source": [
    "## Initialize preloading libraries and Synapse logger API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0802aac-632c-474a-b312-0ad89ceb2c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "common.initialize_preloading()\n",
    "# initialize synapse logger\n",
    "synapse_logger_init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed46a62-994c-4c9f-ba70-7870c2a9028f",
   "metadata": {},
   "source": [
    "## Load Habana TensorFlow modules and aquire Habana Gaudi device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdafaaee-a3a3-4f0f-a3b3-c26f4aa331dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-08 03:30:50.205345: I tensorflow/core/framework/kernel_def_builder.cc:43] 0\n",
      "2021-09-08 03:30:50.205402: I tensorflow/core/framework/kernel_def_builder.cc:43] 1\n",
      "2021-09-08 03:30:50.205433: I tensorflow/core/framework/kernel_def_builder.cc:43] 0\n",
      "2021-09-08 03:30:50.205439: I tensorflow/core/framework/kernel_def_builder.cc:43] 1\n",
      "2021-09-08 03:30:50.205452: I tensorflow/core/framework/kernel_def_builder.cc:43] 0\n",
      "2021-09-08 03:30:50.205457: I tensorflow/core/framework/kernel_def_builder.cc:43] 1\n",
      "2021-09-08 03:30:50.205471: I tensorflow/core/framework/kernel_def_builder.cc:43] 0\n",
      "2021-09-08 03:30:50.205476: I tensorflow/core/framework/kernel_def_builder.cc:43] 1\n",
      "2021-09-08 03:30:50.205487: I tensorflow/core/framework/kernel_def_builder.cc:43] 0\n",
      "2021-09-08 03:30:50.205492: I tensorflow/core/framework/kernel_def_builder.cc:43] 1\n",
      "2021-09-08 03:30:50.205507: I tensorflow/core/framework/kernel_def_builder.cc:43] 0\n",
      "2021-09-08 03:30:50.205512: I tensorflow/core/framework/kernel_def_builder.cc:43] 1\n",
      "2021-09-08 03:30:50.205525: I tensorflow/core/framework/kernel_def_builder.cc:43] 0\n",
      "2021-09-08 03:30:50.205530: I tensorflow/core/framework/kernel_def_builder.cc:43] 1\n",
      "2021-09-08 03:30:50.205540: I tensorflow/core/framework/kernel_def_builder.cc:43] 0\n",
      "2021-09-08 03:30:50.205545: I tensorflow/core/framework/kernel_def_builder.cc:43] 1\n",
      "2021-09-08 03:30:50.205558: I tensorflow/core/framework/kernel_def_builder.cc:43] 0\n",
      "2021-09-08 03:30:50.205563: I tensorflow/core/framework/kernel_def_builder.cc:43] 1\n",
      "2021-09-08 03:30:50.205574: I tensorflow/core/framework/kernel_def_builder.cc:43] 0\n",
      "2021-09-08 03:30:50.205579: I tensorflow/core/framework/kernel_def_builder.cc:43] 1\n",
      "2021-09-08 03:30:50.205591: I tensorflow/core/framework/kernel_def_builder.cc:43] 0\n",
      "2021-09-08 03:30:50.205597: I tensorflow/core/framework/kernel_def_builder.cc:43] 1\n",
      "2021-09-08 03:30:50.205609: I tensorflow/core/framework/kernel_def_builder.cc:43] 0\n",
      "2021-09-08 03:30:50.205614: I tensorflow/core/framework/kernel_def_builder.cc:43] 1\n",
      "2021-09-08 03:30:50.205625: I tensorflow/core/framework/kernel_def_bINFO:absl:Devices:\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6902357726086471554\n",
      ", name: \"/device:HPU:0\"\n",
      "device_type: \"HPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3870755147705603603\n",
      "]\n",
      "uilder.cc:43] 0\n",
      "2021-09-08 03:30:50.205630: I tensorflow/core/framework/kernel_def_builder.cc:43] 1\n",
      "2021-09-08 03:30:50.205643: I tensorflow/core/framework/kernel_def_builder.cc:43] 0\n",
      "2021-09-08 03:30:50.205648: I tensorflow/core/framework/kernel_def_builder.cc:43] 1\n",
      "2021-09-08 03:30:50.205658: I tensorflow/core/framework/kernel_def_builder.cc:43] 0\n",
      "2021-09-08 03:30:50.205663: I tensorflow/core/framework/kernel_def_builder.cc:43] 1\n",
      "2021-09-08 03:30:50.205675: I tensorflow/core/framework/kernel_def_builder.cc:43] 0\n",
      "2021-09-08 03:30:50.205681: I tensorflow/core/framework/kernel_def_builder.cc:43] 1\n",
      "2021-09-08 03:30:50.205691: I tensorflow/core/framework/kernel_def_builder.cc:43] 0\n",
      "2021-09-08 03:30:50.205696: I tensorflow/core/framework/kernel_def_builder.cc:43] 1\n",
      "2021-09-08 03:30:50.205709: I tensorflow/core/framework/kernel_def_builder.cc:43] 0\n",
      "2021-09-08 03:30:50.205714: I tensorflow/core/framework/kernel_def_builder.cc:43] 1\n",
      "2021-09-08 03:30:50.205727: I tensorflow/core/framework/kernel_def_builder.cc:43] 0\n",
      "2021-09-08 03:30:50.205732: I tensorflow/core/framework/kernel_def_builder.cc:43] 1\n",
      "2021-09-08 03:30:50.205743: I tensorflow/core/framework/kernel_def_builder.cc:43] 0\n",
      "2021-09-08 03:30:50.205747: I tensorflow/core/framework/kernel_def_builder.cc:43] 1\n",
      "2021-09-08 03:30:50.259721: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-08 03:30:51.602086: W /home/jenkins/workspace/cdsoftwarebuilder/create-tensorflow-module---bpt-d/tensorflow-training/habana_device/habana_device.cpp:162] Init done for library version 1.0.0_7ec4652c_tf2.5.0\n"
     ]
    }
   ],
   "source": [
    "log_info_devices = load_habana_module()\n",
    "logging.info('Devices:\\n%s', log_info_devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4446c9-3a32-4a79-814c-b77faee54310",
   "metadata": {},
   "source": [
    "## Launch ResNet50 training with LARS optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "847d92cc-601b-46b8-8bc4-04fb509a3ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-08 03:30:53.214090: W /home/jenkins/workspace/cdsoftwarebuilder/create-tensorflow-module---bpt-d/tensorflow-training/habana_device/habana_device.cpp:162] Init done for library version 1.0.0_7ec4652c_tf2.5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"logger_levels\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"logger_levels\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"profile_file\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"profile_file\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"dump_config\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"dump_config\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"shuffle_seed\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"shuffle_seed\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"random_flip_left_right_seed\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"random_flip_left_right_seed\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"ls\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"ls\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"loss_scale\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"loss_scale\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"ara\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"ara\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"all_reduce_alg\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"all_reduce_alg\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"gt_mode\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"gt_mode\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"tf_gpu_thread_mode\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"tf_gpu_thread_mode\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"datasets_num_private_threads\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"datasets_num_private_threads\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"bti\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"bti\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"benchmark_test_id\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"benchmark_test_id\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"bld\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"bld\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"benchmark_log_dir\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"benchmark_log_dir\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"gp\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"gp\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"gcp_project\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"gcp_project\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"worker_hosts\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"worker_hosts\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"profile_steps\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"profile_steps\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"global_seed\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"global_seed\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"end_learning_rate\" is not one of (bool, int, float, str). It will be saved as a string.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Type of parameter \"end_learning_rate\" is not one of (bool, int, float, str). It will be saved as a string.\n",
      "INFO:absl:Training 1 epochs, each epoch has 1000 steps, total steps: 1000; Eval 195 steps\n",
      "INFO:absl:Train at step 0 of 1000\n",
      "INFO:absl:Entering training loop with 100 steps, at step 0 of 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/examples/mg_15_4/TensorFlow/common/training/utils.py:144: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/examples/mg_15_4/TensorFlow/common/training/utils.py:144: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "2021-09-08 03:31:04.389583: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-09-08 03:31:04.718445: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2700000000 Hz\n",
      "INFO:absl:step: 100        steps_per_second: 1.05        {'loss': 4.1505466, 'accuracy': 0.64}\n",
      "INFO:absl:Entering training loop with 100 steps, at step 100 of 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 100        steps_per_second: 1.05        {'loss': 4.1505466, 'accuracy': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:TimeHistory: 111.84 seconds, 457.80 examples/second between steps 0 and 200\n",
      "INFO:absl:step: 200        steps_per_second: 6.03        {'loss': 1.0158594, 'accuracy': 1.0}\n",
      "INFO:absl:Entering training loop with 100 steps, at step 200 of 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 200        steps_per_second: 6.03        {'loss': 1.0158594, 'accuracy': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:step: 300        steps_per_second: 6.06        {'loss': 1.015625, 'accuracy': 1.0}\n",
      "INFO:absl:Entering training loop with 100 steps, at step 300 of 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 300        steps_per_second: 6.06        {'loss': 1.015625, 'accuracy': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:TimeHistory: 33.01 seconds, 1550.90 examples/second between steps 200 and 400\n",
      "INFO:absl:step: 400        steps_per_second: 6.05        {'loss': 1.015625, 'accuracy': 1.0}\n",
      "INFO:absl:Entering training loop with 100 steps, at step 400 of 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 400        steps_per_second: 6.05        {'loss': 1.015625, 'accuracy': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:step: 500        steps_per_second: 6.06        {'loss': 1.015625, 'accuracy': 1.0}\n",
      "INFO:absl:Entering training loop with 100 steps, at step 500 of 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 500        steps_per_second: 6.06        {'loss': 1.015625, 'accuracy': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:TimeHistory: 33.06 seconds, 1548.67 examples/second between steps 400 and 600\n",
      "INFO:absl:step: 600        steps_per_second: 6.04        {'loss': 1.015625, 'accuracy': 1.0}\n",
      "INFO:absl:Entering training loop with 100 steps, at step 600 of 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 600        steps_per_second: 6.04        {'loss': 1.015625, 'accuracy': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:step: 700        steps_per_second: 6.05        {'loss': 1.015625, 'accuracy': 1.0}\n",
      "INFO:absl:Entering training loop with 100 steps, at step 700 of 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 700        steps_per_second: 6.05        {'loss': 1.015625, 'accuracy': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:TimeHistory: 33.05 seconds, 1549.07 examples/second between steps 600 and 800\n",
      "INFO:absl:step: 800        steps_per_second: 6.05        {'loss': 1.015625, 'accuracy': 1.0}\n",
      "INFO:absl:Entering training loop with 100 steps, at step 800 of 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 800        steps_per_second: 6.05        {'loss': 1.015625, 'accuracy': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:step: 900        steps_per_second: 6.06        {'loss': 1.0164844, 'accuracy': 1.0}\n",
      "INFO:absl:Entering training loop with 100 steps, at step 900 of 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 900        steps_per_second: 6.06        {'loss': 1.0164844, 'accuracy': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:TimeHistory: 33.03 seconds, 1550.09 examples/second between steps 800 and 1000\n",
      "INFO:absl:step: 1000        steps_per_second: 6.05        {'loss': 1.0177344, 'accuracy': 1.0}\n",
      "INFO:absl:Run stats:\n",
      "{'step_timestamp_log': ['BatchTimestamp<batch_index: 0, timestamp: 1631071857.7869437>', 'BatchTimestamp<batch_index: 200, timestamp: 1631071969.626038>', 'BatchTimestamp<batch_index: 400, timestamp: 1631072002.6641362>', 'BatchTimestamp<batch_index: 600, timestamp: 1631072035.7503839>', 'BatchTimestamp<batch_index: 800, timestamp: 1631072068.8265276>', 'BatchTimestamp<batch_index: 1000, timestamp: 1631072101.8778355>'], 'train_finish_time': 1631072101.8968284, 'avg_exp_per_second': 1048.7455096379886}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1000        steps_per_second: 6.05        {'loss': 1.0177344, 'accuracy': 1.0}\n"
     ]
    }
   ],
   "source": [
    "if flags.FLAGS.global_seed:\n",
    "    tf.random.set_seed(flags.FLAGS.global_seed)\n",
    "\n",
    "with HabanaEnvVariables(env_args):\n",
    "    with dump_callback():\n",
    "        model_helpers.apply_clean(flags.FLAGS)\n",
    "        with logger.benchmark_context(flags.FLAGS):\n",
    "            stats =run(flags.FLAGS)\n",
    "        logging.info('Run stats:\\n%s', stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45de297-cbb4-4547-8f71-269bf41f4e33",
   "metadata": {},
   "source": [
    "## Load TensorBoard to display training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "above-mozambique",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9ab37c148a0c379e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9ab37c148a0c379e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --bind_all --logdir /root/tmp/resnet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21207d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
