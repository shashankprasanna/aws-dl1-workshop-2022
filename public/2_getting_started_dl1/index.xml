<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2. Deep Learning Training with Habana Models on Getting Started with Amazon SageMaker Studio</title>
    <link>/2_getting_started_dl1.html</link>
    <description>Recent content in 2. Deep Learning Training with Habana Models on Getting Started with Amazon SageMaker Studio</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="/2_getting_started_dl1/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>2.1 Download habana Models</title>
      <link>/2_getting_started_dl1/download_habana_models.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/2_getting_started_dl1/download_habana_models.html</guid>
      <description>Training on Habana from the Model-References GitHub repository Habana has a Model-References GitHub Page with a list of reference models that are optimized to run on Gaudi There are models for TensorFlow and PyTorch covering Computer Vision and NLP usages
Focus will be on TensorFlow ResNet50 Keras and BERT examples in this workshop. In general, when using the Full DLAMI, the user will need to to the following to run Habana models:</description>
    </item>
    
    <item>
      <title>2.2 ResNet50 Keras Notebook</title>
      <link>/2_getting_started_dl1/rs50.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/2_getting_started_dl1/rs50.html</guid>
      <description></description>
    </item>
    
    <item>
      <title>2.3 Bert Notebook</title>
      <link>/2_getting_started_dl1/bert.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/2_getting_started_dl1/bert.html</guid>
      <description></description>
    </item>
    
  </channel>
</rss>